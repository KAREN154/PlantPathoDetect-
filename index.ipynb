{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAREN154/PlantPathoDetect-/blob/main/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEziwMauhjRv"
      },
      "source": [
        "# PLANTPATHODETECT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td5_XqQZhjSE"
      },
      "source": [
        "\n",
        "<img src =\"Images/main.jpeg\" width = \"1000\" height =\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9gdWGTXhjSH"
      },
      "source": [
        "<h1>1. Business Understanding</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQsU_-wRhjSK"
      },
      "source": [
        "<h2>1.1 Business Overview</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPDlGar4hjSN"
      },
      "source": [
        "Agriculture is crucial for food security and economic stability, yet essential crops like maize, potatoes, and tomatoes face rising threats from diseases that significantly reduce yields and impact farmers' livelihoods. In regions reliant on these crops, such challenges lead to economic strain, increased pesticide use, and food shortages, affecting entire communities. This project aims to address these issues by developing a machine learning-powered image classification system for early disease detection. By enabling farmers to upload crop images to a web-based platform for real-time analysis and treatment recommendations, the solution empowers them with vital insights, helping to protect yields and sustain food production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ihqdW-whjSQ"
      },
      "source": [
        "<h2>1.2 Problem Statement<h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLm2GygRhjST"
      },
      "source": [
        "Crop diseases significantly reduce yields and incomes for farmers, impacting food security and economic stability, especially in regions with limited resources. In Kenya, farmers often lack access to timely and accurate disease detection, relying on traditional methods that delay intervention and increase losses. This project addresses the need for a more efficient, accessible solution by developing a machine learning-based system for early disease detection in maize, potatoes, and tomatoes, providing farmers with quick, actionable insights to improve crop health and productivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1nAXvishjSW"
      },
      "source": [
        "<h2>1.3 Proposed Solutions</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZoLoNbkhjSZ"
      },
      "source": [
        "1. Machine Learning-Based Image Classification: Developing a machine learning model, specifically a convolutional neural network (CNN), to classify images of maize, potatoes, and tomatoes for early disease detection. This model will be trained to recognize various crop diseases accurately.\n",
        "\n",
        "2. Web-Based Platform: Creating a user-friendly web application where farmers can upload images of their crops for real-time analysis. The platform will offer diagnosis results and treatment recommendations, making disease management accessible to farmers with limited resources.\n",
        "\n",
        "3. Data Collection and Preprocessing: Building a robust, diverse dataset of crop images to enhance model accuracy and ensure it can detect diseases across different crop species and environmental conditions.\n",
        "\n",
        "4. Agile Development and Feedback Loop: Employing an iterative, agile development approach to continuously refine the model and application based on user feedback and evolving needs.\n",
        "\n",
        "5. Integration with Local Agriculture Practices: Tailoring the solution to the specific agricultural challenges in Kenya, ensuring that the system aligns with local crop health practices and disease management strategies.\n",
        "\n",
        "6. Educational Resources and Support: Providing guidance on disease prevention and sustainable farming practices through the web application to further support farmers in maintaining crop health."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ4SCfBphjSb"
      },
      "source": [
        "## 1.4 Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QzgkBOthjSd"
      },
      "source": [
        "### 1.4.1 General Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLhVV9t3hjSe"
      },
      "source": [
        "To develop a web-based application that facilitates early detection and prediction of crop diseases in maize, potatoes, and tomatoes using machine learning-based image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1WFoikghjSg"
      },
      "source": [
        "### 1.4.2 Specific Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQPppog5hjSh"
      },
      "source": [
        "1. **Data Collection and Preprocessing**: To collect and preprocess a diverse dataset of images capturing common diseases affecting maize, potatoes, and tomatoes.\n",
        "2. **Model Development**: To design and train a convolutional neural network (CNN) for accurate image classification of crop diseases.\n",
        "3. **Application Deployment**: To implement the trained model within a user-friendly web application where farmers can upload images for disease diagnosis.\n",
        "4. **System Evaluation and Feedback**: To assess the model’s performance, gather user feedback, and iteratively refine the application for practical use by local farmers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgCMOMOIhjSj"
      },
      "source": [
        "<h2>1.5 Research Questions</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnZtiFc0hjSl"
      },
      "source": [
        "\n",
        "1. What crop diseases can be effectively detected in maize, potatoes, and tomatoes using image classification?\n",
        "2. How accurate is the proposed machine learning model in identifying diseases in these crops?\n",
        "3. What features are necessary for a web-based application to aid farmers in disease diagnosis?\n",
        "4. How can the web application provide actionable recommendations based on detected diseases?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTw_KIA0hjSm"
      },
      "source": [
        "<h2>1.6 Justification</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4VpktVThjSm"
      },
      "source": [
        "This research addresses the pressing issue of crop diseases, which impacts farmers’ livelihoods and food security. Providing an accessible tool for disease detection empowers farmers with knowledge, enabling timely action. The project contributes to agricultural technology and highlights machine learning's potential in enhancing agricultural practices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KiPoJuwhjSo"
      },
      "source": [
        "<h2>1.7 Proposed Research and System Methodologies</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx1xq42lhjSp"
      },
      "source": [
        "\n",
        "The project will collect data from public agricultural databases and farmer collaborations, focusing on maize, potatoes, and tomatoes. A CNN will be used for its effectiveness in image classification, and an Agile development process will ensure iterative feedback from users. Key tools include Python for model development, Flask for the web application, and TensorFlow for deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lznz674ZhjSq"
      },
      "source": [
        "<h2>1.8 Scope</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cflaZMPihjSr"
      },
      "source": [
        "\n",
        "The research focuses on common diseases affecting maize, potatoes, and tomatoes in Kenya, targeting smallholder farmers who may lack resources for effective disease management. Limitations may include data variability and disease manifestation differences across crop species. This study is confined to digital image analysis and does not include physical disease testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ETXSHYhjSs"
      },
      "source": [
        "<h2>1.9 StakeHolders</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu7ixfS7hjSt"
      },
      "source": [
        "1. Farmers: Smallholder and commercial farmers, particularly in regions where crop diseases like those affecting maize, potatoes, and tomatoes are prevalent. They are the end-users who will directly benefit from the disease detection tool.\n",
        "\n",
        "2. Agricultural Extension Officers: Professionals who work closely with farmers, providing advice and support in crop management. They may use this tool to assist farmers in disease identification and treatment recommendations.\n",
        "\n",
        "3. Agricultural Research Institutions: Organizations focused on agricultural technology and innovation. They may be interested in the data, findings, and outcomes to support further research on crop diseases and digital agricultural solutions.\n",
        "\n",
        "4. Government and Policymakers: Officials responsible for food security and agricultural productivity initiatives. They might use insights from the project to shape policies and support digital innovations that aid farmers.\n",
        "\n",
        "5. Technology and Data Science Professionals: Individuals or teams involved in the development, maintenance, and improvement of the machine learning model and web application.\n",
        "\n",
        "6. Non-Governmental Organizations (NGOs): Organizations that work with smallholder farmers to improve food security and promote sustainable farming practices could also benefit from the tool by integrating it into their support programs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2WncevphjSu"
      },
      "source": [
        "<h1>Data Understanding</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuUthX2GhjSu"
      },
      "source": [
        "The dataset used in this project is sourced from PlantVillage and comprises 70,000 high-quality images of both healthy and diseased plant leaves from nine distinct species. This dataset is meticulously organized into three splits—train, test, and validation—ensuring consistent categories across each split. It offers an excellent foundation for machine learning research and applications in plant disease detection and classification.\n",
        "\n",
        "Ideal for both agricultural experts and machine learning practitioners, this diverse dataset captures a broad range of plant species, disease types, and growth stages. By leveraging this dataset, the project aims to advance research in plant pathology and support farmers in enhancing crop health and productivity, ultimately contributing to more sustainable agricultural practices.\n",
        "\n",
        "Link to The Plant Village Website [Plant Village](https://plantvillage.psu.edu/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI19yuGyh32S",
        "outputId": "5027ba22-3e65-47ba-fa70-81845576d06f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/MyDrive/PlantPathoDetect-'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD308cZIiPMg",
        "outputId": "8919e6e4-365c-460c-9485-18ce1d6a122a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data-augementation.py  index.ipynb\tPlantPathoDetectDocumentation.docx\n",
            "data-processing.py     LICENSE.unknown\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/PlantPathoDetect-'\n",
        "\n",
        "# To access different directories , you can create path variables\n",
        "\n",
        "data_path =f\"{base_path}/data\"\n",
        "images_path = f\"{data_path}/Images\"\n",
        "labels_path = f\"{data_path}/tomato-images\"\n",
        "\n",
        "\n",
        "# To verify the paths and see the contents\n",
        "print(\"Data Directory contents:\")\n",
        "!ls{data_path}\n",
        "\n",
        "print(\"\\nImages Directory contents:\")\n",
        "!ls{images_path}\n",
        "\n",
        "print(\"\\nLabels Directory contents:\")\n",
        "!ls{labels_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk-cvfkajKmQ",
        "outputId": "a5150de4-d03a-4042-b4d4-7a5b0f9cd56a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Directory contents:\n",
            "/bin/bash: line 1: ls/content/drive/MyDrive/PlantPathoDetect-/data: No such file or directory\n",
            "\n",
            "Images Directory contents:\n",
            "/bin/bash: line 1: ls/content/drive/MyDrive/PlantPathoDetect-/data/Images: No such file or directory\n",
            "\n",
            "Labels Directory contents:\n",
            "/bin/bash: line 1: ls/content/drive/MyDrive/PlantPathoDetect-/data/tomato-images: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkgSS1oDhjSv"
      },
      "source": [
        "***Import necessary libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCsyb6FChjSx",
        "outputId": "8c7d3a40-564d-4de8-f1a3-969f816a290e"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\USER\\OneDrive\\Documents\\PlantPathoDetect\\patho-p\\Lib\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from keras.models import sequential\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\USER\\OneDrive\\Documents\\PlantPathoDetect\\patho-p\\Lib\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# from tensorflow.keras.callbacks import ModelCheckpo\n",
        "import tensorflow as tf\n",
        "# from keras.models import sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG1sYgr0hjS8"
      },
      "source": [
        "***Function to create a DataFrame***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMAxyBH2hjS9"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66dlcRlIhjS-",
        "outputId": "32400f90-d7b4-408f-ebe3-32f91fd17dd4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\T'\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\T'\n",
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7376\\671312597.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
            "  train_tomato = \"data\\Tomato\\Train\"\n",
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7376\\671312597.py:3: SyntaxWarning: invalid escape sequence '\\T'\n",
            "  test_tomato = \"data\\Tomato\\Test\"\n",
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7376\\671312597.py:4: SyntaxWarning: invalid escape sequence '\\T'\n",
            "  val_tomato = \"data\\Tomato\\Val\"\n"
          ]
        }
      ],
      "source": [
        "# Set the paths to the train, test, and validation directories\n",
        "train_tomato = \"data\\Tomato\\Train\"\n",
        "test_tomato = \"data\\Tomato\\Test\"\n",
        "val_tomato = \"data\\Tomato\\Val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXlGy1kdhjTA",
        "outputId": "62cd83a6-5d58-4211-e09d-c7c80f529e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bacterial Spot', 'Early Blight', 'Healthy', 'Late Blight', 'Septoria Leaf Spot', 'Yellow Leaf Curl Virus']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(train_tomato))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFDgniBvhjTE",
        "outputId": "e50ff91d-fca6-430b-fc98-3590def65c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial Spot\n",
            "\n",
            "Early Blight\n",
            "\n",
            "Healthy\n",
            "\n",
            "Late Blight\n",
            "\n",
            "Septoria Leaf Spot\n",
            "\n",
            "Yellow Leaf Curl Virus\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for foldername in os.listdir(train_tomato):\n",
        "    print(foldername +\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTp46m6UhjTJ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "def img_to_array(dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for folderName in os.listdir(train_tomato):\n",
        "        folder_dir = os.path.join(train_tomato, folderName)\n",
        "        if os.path.isdir(folder_dir):\n",
        "            for fileName in os.listdir(folder_dir):\n",
        "                if fileName.endswith('.JPG'):\n",
        "                    img = Image.open(os.path.join(folder_dir, fileName))\n",
        "                    resized_img = img.resize((128, 128))\n",
        "                    img_arr = np.array(resized_img)\n",
        "                    images.append(img_arr)\n",
        "                    labels.append(folderName)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    print(images.shape, labels.shape)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8OdIxS5hjTM",
        "outputId": "74b8f223-6459-4291-8c0c-bc7d7558c948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10958, 128, 128, 3) (10958,)\n",
            "(10958, 128, 128, 3) (10958,)\n",
            "(10958, 128, 128, 3) (10958,)\n"
          ]
        }
      ],
      "source": [
        "# Read and store images from the train directory\n",
        "train_images, train_labels = img_to_array(train_tomato)\n",
        "\n",
        "# Read and store images from the test directory\n",
        "test_images, test_labels = img_to_array(test_tomato)\n",
        "\n",
        "# Read and store images from the validation directory\n",
        "val_images, val_labels = img_to_array(val_tomato)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vqv35iBhjTO"
      },
      "source": [
        " Reading the images and converting them into np.arrays, the visualized images prove that it has been done properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYJWfHMMhjTQ",
        "outputId": "b84379d2-b518-4f56-b772-c43a98d8aa1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bacterial Spot' 'Bacterial Spot' 'Bacterial Spot' ...\n",
            " 'Yellow Leaf Curl Virus' 'Yellow Leaf Curl Virus'\n",
            " 'Yellow Leaf Curl Virus']\n"
          ]
        }
      ],
      "source": [
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D-uBuBXhjTR",
        "outputId": "948feadc-b223-41ca-da28-f2b657633512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Bacterial Spot', 'Bacterial Spot', 'Bacterial Spot', ...,\n",
              "       'Yellow Leaf Curl Virus', 'Yellow Leaf Curl Virus',\n",
              "       'Yellow Leaf Curl Virus'], dtype='<U22')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-pBYYgphjTT"
      },
      "outputs": [],
      "source": [
        "# # Normalize pixel values to the range of 0-1\n",
        "# train_tomato = train_tomato.astype('float32') / 255.0\n",
        "# val_tomato = val_tomato.astype('float32') / 255.0\n",
        "# test_tomato= test_tomato.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afLwaCkEhjTi"
      },
      "outputs": [],
      "source": [
        "# # Save train_images\n",
        "# np.save('/train_images.npy', train_tomato)\n",
        "\n",
        "# # Save val_images\n",
        "# np.save('val_images.npy', val_tomato)\n",
        "\n",
        "# # Save test_images\n",
        "# np.save('test_images.npy', test_tomato)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aUCHAkJhjTj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming 'train_images' and 'train_labels' are your NumPy arrays\n",
        "\n",
        "# Create an instance of ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=60,  # Rotation range in degrees\n",
        "    vertical_flip=True  # Enable vertical flipping\n",
        ")\n",
        "\n",
        "# Reshape train_images to 4D (required by ImageDataGenerator)\n",
        "train_images_4D = train_images.reshape(train_images.shape\n",
        "[0], train_images.shape[1], train_images.shape[2], 3)\n",
        "\n",
        "# Generate augmented images\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for img, label in zip(train_images_4D, train_labels):\n",
        "    img_batch = np.expand_dims(img, axis=0)\n",
        "    aug_iter = datagen.flow(img_batch, batch_size=1)\n",
        "    for _ in range(4):  # Generate 4 augmented images for each original image\n",
        "        augmented_img = next(aug_iter)[0].astype(np.uint8)\n",
        "        augmented_images.append(augmented_img)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "# Convert augmented images and labels to NumPy arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "# Reshape augmented_images to 4D (original shape)\n",
        "augmented_images = augmented_images.reshape(\n",
        "    augmented_images.shape[0], train_images.shape[1], train_images.shape[2], 3\n",
        ")\n",
        "\n",
        "# Concatenate augmented and original images and labels\n",
        "final_train_images = np.concatenate((train_images, augmented_images), axis=0)\n",
        "final_train_labels = np.concatenate((train_labels, augmented_labels), axis=0)\n",
        "\n",
        "# Shuffle the data\n",
        "shuffle_indices = np.random.permutation(final_train_images.shape[0])\n",
        "final_train_images = final_train_images[shuffle_indices]\n",
        "final_train_labels = final_train_labels[shuffle_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbHetoXvhjTm"
      },
      "source": [
        " preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbbIJzJThjTo"
      },
      "source": [
        "Handles all preprocessing steps\n",
        "Features:\n",
        "\n",
        "Label encoding and one-hot encoding\n",
        "Image normalization\n",
        "Detailed statistics and distribution reporting\n",
        "Organized class structure with helper methods\n",
        "Comprehensive documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnCKIu22hjTp"
      },
      "source": [
        "#### Data Augementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO4b9fqHhjTq"
      },
      "source": [
        "Handles all data augmentation tasks\n",
        "Features:\n",
        "\n",
        "- Customizable augmentation parameters\n",
        "- Generator creation for training\n",
        "- Augmentation preview functionality\n",
        "- Detailed documentation\n",
        "- Visual inspection of augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXLf6-5WhjTs"
      },
      "outputs": [],
      "source": [
        "# Initialize augmentor\n",
        "augmentor = DataAugmentor()\n",
        "\n",
        "# Create generator for training\n",
        "train_generator = augmentor.create_generator(\n",
        "    processed_images['train'],\n",
        "    processed_labels['train'],\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Optionally, preview augmentations\n",
        "sample_image = processed_images['train'][0]\n",
        "augmentor.preview_augmentations(sample_image, num_augmentations=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hctvBDqshjTu"
      },
      "source": [
        "# Set the paths to the train, test, and validation directories\n",
        "train_dir = '/kaggle/input/plant-village-dataset-updated/Tomato/Train'\n",
        "test_dir = '/kaggle/input/plant-village-dataset-updated/Tomato/Test'\n",
        "val_dir = '/kaggle/input/plant-village-dataset-updated/Tomato/Val'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "patho-p",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}